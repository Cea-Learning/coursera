{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Neighbourhoods\n",
    "### A comparative analysis of Lagos to Kigali"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Install Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install bs4\n",
    "!pip3 install requests\n",
    "!pip3 install html5lib"
   ]
  },
  {
   "source": [
    "### Import Dependencies\n",
    " We import Beautifulsoup dependency for web scraping of wikipedia page, requests for making http calls, html5lib a type of beautifulsoup parser for html files and pandas for working with extracted data in the form of a dataframe\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html5lib\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "## Data Collection - Import Files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "cost_of_living_data = pd.read_csv(\"cost_of_living.csv\")\n",
    "neighbourhoods_data = pd.read_csv(\"neighbourhoods.csv\")\n",
    "cost_of_living_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_data"
   ]
  },
  {
   "source": [
    "## Data Preprocessing - Convert Files into DataFrame\n",
    "\n",
    "we need to clean the cost_of_living_data to remove the extra currencies. i decided to use the rwandan franc when comparing, therefore we will be the alternative sum in Naira."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneccesary_amount (value):\n",
    "    value =value.split(\"R\")[0]\n",
    "    value = value.strip()\n",
    "    value = value.replace(\",\",'')\n",
    "    value = float(value)\n",
    "    return value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_of_living_data[\"Kigali\"]= cost_of_living_data[\"Kigali\"].apply(remove_unneccesary_amount)\n",
    "cost_of_living_data[\"Lagos\"] = cost_of_living_data[\"Lagos\"].apply(remove_unneccesary_amount)\n",
    "cost_of_living_data.head(10)"
   ]
  },
  {
   "source": [
    "we basically need to compare the amounts for kigali and lagos and not really the type of goods. so we create a new dataframe of the information we need"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "living_cost = cost_of_living_data[[\"Kigali\",\"Lagos\"]]\n",
    "living_cost.head()"
   ]
  },
  {
   "source": [
    "Likewise we process the neighbourhoods data adding the longitude and latitude of each area to the csv file and saving it for future reuse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_data(value):\n",
    "    geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "    location = geolocator.geocode(value)\n",
    "    if location is not None: \n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "        return latitude, longitude\n",
    "    return None, None\n",
    "  \n"
   ]
  },
  {
   "source": [
    "\n",
    "new_cols =[\"Latitude\",\"Longitude\"]  \n",
    "for n,col in enumerate(new_cols):\n",
    "       neighbourhoods_data[col] = neighbourhoods_data[['Neighborhoods','City']].agg(\",\".join, axis =1).apply(lambda x: get_location_data(x)[n])\n",
    "neighbourhoods_data[neighbourhoods_data[\"Latitude\"].isnull()][\"Latitude\"].value_counts()\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_coordinates = pd.read_csv(\"Missing_Coordinates.csv\")\n",
    "not_found_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_data.set_index(\"Neighborhoods\", inplace=True)\n",
    "not_found_coordinates.set_index(\"Neighborhoods\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for val in not_found_coordinates.index:\n",
    "    neighbourhoods_data.loc[val,[\"Latitude\",\"Longitude\"]] = not_found_coordinates.loc[val,[\"Latitude\", \"Longitude\"]]\n",
    "neighbourhoods_data.reset_index(inplace=True)\n",
    "neighbourhoods_data[neighbourhoods_data[\"Latitude\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_data = neighbourhoods_data[[neighbourhoods_data.columns[1]] +[neighbourhoods_data.columns[2]]  + [neighbourhoods_data.columns[0]]+ list(neighbourhoods_data.columns[3:])]\n",
    "neighbourhoods_data"
   ]
  },
  {
   "source": [
    "we see that all areas now have latitude and longitude."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Get the Latitude and Longitude based on Postal Codes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exploring Cost Of Living\n",
    "  \n",
    "We want to analyze the cost of living in Lagos vs Kigali to understand trends in price distribution and understand which area is more costly to live in. We would be using a normal independent t-test to check if there is a significant difference between living in Lagos and living in Kigali. Also a correlation analysis to see if price are distributed in the same order for both Kigali and Lagos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import plotly.express as px"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### first we create a box plot to check if location causes significant difference in price trend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kigali_prices = living_cost[[\"Kigali\"]]\n",
    "kigali_prices[\"Location\"] = \"Kigali\"\n",
    "kigali_prices.rename(columns={'Kigali': \"Prices\"}, inplace=True)\n",
    "lagos_prices = living_cost[[\"Lagos\"]]\n",
    "lagos_prices[\"Location\"] = \"Lagos\"\n",
    "lagos_prices.rename(columns={'Lagos': \"Prices\"}, inplace=True)\n",
    "result = pd.concat([kigali_prices, lagos_prices])\n",
    "# scaler =preprocessing.StandardScaler()\n",
    "# result['Prices']= scaler.fit_transform(result[[\"Prices\"]])\n",
    "sns.boxplot(x= \"Location\", y=\"Prices\", data=result)"
   ]
  },
  {
   "source": [
    "The boxplot shows that the trend of prices for products are significantly similiar for both lagos and Kigali, therefore the meal for two persons would be more expensive than the meal for one person in Kigali as it is in Lagos. Therefore location has no significant effect on trends of product prices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "living_cost[['Kigali','Lagos']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(living_cost['Lagos'], living_cost['Kigali'])\n",
    "pearson_coef"
   ]
  },
  {
   "source": [
    "We see that the trend of prices in both cities are correlated but not strongly. A final independent T-test we help us understand if there is a significant difference though in the cost of living in Kigali versus Lagos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "stats.ttest_ind(living_cost[\"Kigali\"], living_cost[\"Lagos\"], equal_var=False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "A large pValue of 0.6729 shows that we cannot reject the null hypothesis of identical means. Therefore there is no significant difference between the cost average cost of living in Lagos and that of Kigali."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exploring Similarities (Areas/Neighbourhoods)\n",
    " Having seen that there is no siginificant difference in the cost of living in both cities, we explore areas and neighbourhoods to find  similarities between them "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We install and import the neccessary packages for our exploration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import folium\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_coordinates(place):\n",
    "    geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "    location = geolocator.geocode(place)\n",
    "    latitude = location.latitude\n",
    "    longitude = location.longitude\n",
    "    print('The geograpical coordinate of Republic of Congo are {}, {}.'.format(latitude, longitude))\n",
    "    return (latitude,longitude)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Map of Cities with its neighbourhoods superimposed on it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a place that is at the middle of both Nigeria and Rwanda so we can easily represent both places on the map\n",
    "cities_map = folium.Map(location=get_coordinates(\"Republic of Congo\"), zoom_start=5)\n",
    "for lat, lng, label in zip(neighbourhoods_data['Latitude'], neighbourhoods_data['Longitude'], neighbourhoods_data['Neighborhoods']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(cities_map)\n",
    "cities_map"
   ]
  },
  {
   "source": [
    "### Using Forsquare API\n",
    "using foursquare api, we collect data about places nearby to a specific longitude and latitude"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '************************' # your Foursquare ID\n",
    "CLIENT_SECRET = '*********************' # your Foursquare Secret\n",
    "ACCESS_TOKEN = \"***************\" # your FourSquare Access Token\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100"
   ]
  },
  {
   "source": [
    "Let explore the neighbourhoods by getting the top nearby venues for each neighbourhood in north york. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getNearbyVenues(city, names, latitudes, longitudes, radius=1000):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for city_name, name, lat, lng in zip(city, names, latitudes, longitudes):\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]\n",
    "        print(results)\n",
    "        results = results['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            city_name,\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            venue['venue']['name'], \n",
    "            venue['venue']['location']['lat'], \n",
    "            venue['venue']['location']['lng'],  \n",
    "            venue['venue']['categories'][0]['name']) for venue in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = [\"City\",'Neighborhoods',\n",
    "                  'Neighborhoods Latitude', \n",
    "                  'Neighborhoods Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues = getNearbyVenues(neighbourhoods_data[\"City\"], neighbourhoods_data[\"Neighborhoods\"], neighbourhoods_data[\"Latitude\"], neighbourhoods_data[\"Longitude\"])"
   ]
  },
  {
   "source": [
    "Let split the nearby_venues into two sets for Kigali and Lagos since we are trying to compare both cities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues_lagos = nearby_venues[nearby_venues['City'] == \"Lagos\"]\n",
    "nearby_venues_kigali = nearby_venues[nearby_venues['City'] == \"Kigali\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues_kigali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues_lagos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nearby_venues_kigali.groupby(\"Neighborhoods\").count().sort_values([\"City\"], ascending=False).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_venues_lagos.groupby(\"Neighborhoods\").count().sort_values([\"City\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the neighborhoods in north york have no nearby places with a 500m range"
   ]
  },
  {
   "source": [
    "## Analyzing Neighbourhoods\n",
    "To be able to use this information for clustering we create dummy variables for each category"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add neighborhood column back to dataframe\n",
    "def analyse_neighbourhood(city_venues, num_top_venues):\n",
    "    neighbourhood_dummies = pd.get_dummies(city_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "    neighbourhood_dummies['Neighborhoods'] = city_venues['Neighborhoods'] \n",
    "# move neighborhood column to the first column\n",
    "\n",
    "    fixed_columns = [neighbourhood_dummies.columns[-1]] + list(neighbourhood_dummies.columns[:-1])\n",
    "    neighbourhood_dummies = neighbourhood_dummies[fixed_columns]\n",
    "    neighbourhood_grouped = neighbourhood_dummies.groupby(\"Neighborhoods\").mean().reset_index()\n",
    "    columns = [\"Neighborhoods\"]\n",
    "    indicators = ['st', 'nd', 'rd']\n",
    "    for ind in np.arange(num_top_venues):\n",
    "        try:\n",
    "            columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "        except:\n",
    "            columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "    neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "    neighborhoods_venues_sorted['Neighborhoods'] = neighbourhood_grouped['Neighborhoods']\n",
    "    for ind in np.arange(neighbourhood_grouped.shape[0]):\n",
    "        neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(neighbourhood_grouped.iloc[ind, :], num_top_venues)\n",
    "      \n",
    "    return neighbourhood_grouped, neighborhoods_venues_sorted\n",
    "\n",
    "\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    categories_list=[]\n",
    "    count = 0\n",
    "    for x in row_categories_sorted:\n",
    "        if x > 0.0:\n",
    "            categories_list.extend(row_categories_sorted.index.values[count:count+1])\n",
    "        else:\n",
    "            categories_list.extend([np.NaN])\n",
    "        count= count+1\n",
    "    return categories_list[0: num_top_venues]\n",
    "\n"
   ]
  },
  {
   "source": [
    "Lets print 10 top venues for Lagos neighborhoods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,top_10_venues_in_lagos = analyse_neighbourhood( nearby_venues_lagos, 10)\n",
    "top_10_venues_in_lagos"
   ]
  },
  {
   "source": [
    "Also we get top 10 venues in Kigali"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,top_10_venues_in_kigali = analyse_neighbourhood( nearby_venues_kigali, 10)\n",
    "top_10_venues_in_kigali"
   ]
  },
  {
   "source": [
    "### Get Most Common Places"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique list of most_common_places in all neigh\n",
    "def get_most_common_place(neighborhoods_venues_sorted,val):\n",
    "    common_places_list = [venue for venues in neighborhoods_venues_sorted.iloc[:,val:].to_numpy() for venue in venues if str(venue) != 'nan' and str(venue)!=\"\"]\n",
    "    common_venues = pd.Series(np.array(common_places_list)).value_counts()\n",
    "    most_common_venues = common_venues.to_frame()\n",
    "    most_common_venues.reset_index(inplace =True)\n",
    "    most_common_venues.columns = [\"Venues\",\"Count\"]\n",
    "    return most_common_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_venues_in_lagos = get_most_common_place(top_10_venues_in_lagos ,1)\n",
    "Ten_most_common_venues_in_lagos = most_common_venues_in_lagos.head(10)\n",
    "Ten_most_common_venues_in_lagos"
   ]
  },
  {
   "source": [
    "Likewise we get 10 most common places in Kigali"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_venues_in_kigali = get_most_common_place(top_10_venues_in_kigali ,1)\n",
    "Ten_most_common_venues_in_kigali = most_common_venues_in_kigali.head(10)\n",
    "Ten_most_common_venues_in_kigali"
   ]
  },
  {
   "source": [
    "## Clustering Neighborhoods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We want to cluster similiar neighbourhoods in both lagos and kigali. We use K-means Clustering method, an unspervised machine learning method to know cluster these neighbourhoods."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First we determine the number of clusters that is the best fit for clustering the neighbourhoods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "neighbourhood_grouped,neighborhoods_venues_sorted = analyse_neighbourhood(nearby_venues,10)\n",
    "neighborhoods_venues_sorted\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_clustering_data = neighbourhood_grouped.drop(\"Neighborhoods\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "K = range(1,12)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(neighbourhood_clustering_data)\n",
    "    inertia.append(kmeans.inertia_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "so we use K = 3 as our number of clusters\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans( n_clusters = 4, init=\"k-means++\").fit(neighbourhood_clustering_data)\n",
    "if 'Cluster Labels' in neighborhoods_venues_sorted.columns:\n",
    "    del neighborhoods_venues_sorted[\"Cluster Labels\"]\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "ny_merged = neighbourhoods_data\n",
    "\n",
    "ny_merged = ny_merged.join(neighborhoods_venues_sorted.set_index('Neighborhoods'), on='Neighborhoods')\n",
    "\n",
    "# remove the neighborhood without any nearby venues\n",
    "# ny_merged.dropna(inplace=True, )\n",
    "ny_merged.drop(ny_merged[ny_merged[\"Cluster Labels\"].isna()].index, inplace=True)\n",
    "ny_merged\n",
    "ny_merged[\"Cluster Labels\"] = ny_merged[\"Cluster Labels\"].astype(int)\n",
    "ny_merged.reset_index(drop=True, inplace=True)\n",
    "ny_merged.replace(np.NaN, '', inplace=True)\n",
    "ny_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters = folium.Map(location=get_coordinates(\"Republic of Congo\"), zoom_start=5)\n",
    "kclusters =4\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(ny_merged['Latitude'], ny_merged['Longitude'], ny_merged['Neighborhoods'], ny_merged\n",
    "['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cluster =ny_merged.loc[ny_merged['Cluster Labels'] == 0, ny_merged.columns[[0]+[2] + list(range(5, ny_merged.shape[1]))]]\n",
    "first_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cluster =ny_merged.loc[ny_merged['Cluster Labels'] == 1, ny_merged.columns[[0]+[2] + list(range(5, ny_merged.shape[1]))]]\n",
    "second_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_cluster =ny_merged.loc[ny_merged['Cluster Labels'] == 2, ny_merged.columns[[0]+[2] + list(range(5, ny_merged.shape[1]))]]\n",
    "third_cluster"
   ]
  },
  {
   "source": [
    "from the clusterization we see that the first clusters is a very busy neighbourhood, the second cluster is moderatively busy with fewer places, the third place is a more quiet neighbourhood with more venues like parks and movie theaters and finally the last venue with relatively few places to visit nearby."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_cluster =ny_merged.loc[ny_merged['Cluster Labels'] == 3, ny_merged.columns[[0]+[2] + list(range(5, ny_merged.shape[1]))]]\n",
    "fourth_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_cluster =ny_merged.loc[ny_merged['Cluster Labels'] == 4, ny_merged.columns[[0]+[2] + list(range(5, ny_merged.shape[1]))]]\n",
    "fifth_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [first_cluster, second_cluster, third_cluster, fourth_cluster, fifth_cluster]\n",
    "for cluster in clusters:\n",
    "    print(get_most_common_place(cluster, 3).head(10),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}